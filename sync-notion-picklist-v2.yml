name: Sync Notion Pick List

# This workflow syncs Pick List data from Notion Injection Tracker
# Uses the NEW data_sources API (version 2025-09-03) for multi-source databases

on:
  schedule:
    - cron: '*/15 6-22 * * *'  # Every 15 min during lab hours (6am-10pm UTC)
  workflow_dispatch:  # Allow manual trigger

jobs:
  sync:
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        
      - name: Query Notion Data Source
        env:
          NOTION_TOKEN: ${{ secrets.NOTION_TOKEN }}
        run: |
          echo "ðŸ”„ Querying Notion Injection Tracker..."
          
          # Use the NEW /v1/data_sources endpoint with API version 2025-09-03
          # Data source ID: 848a619d-5513-4f52-8b6e-97a1d284c465
          
          curl -s -X POST \
           "https://api.notion.com/v1/data_sources/848a619d55134f528b6e97a1d284c465/query" \
            -H "Authorization: Bearer $NOTION_TOKEN" \
            -H "Notion-Version: 2025-09-03" \
            -H "Content-Type: application/json" \
            -d '{
              "page_size": 100
            }' > notion_page1.json
          
          # Check for errors
          if grep -q '"object":"error"' notion_page1.json; then
            echo "âŒ API Error:"
            cat notion_page1.json
            exit 1
          fi
          
          echo "âœ… First page fetched"
          
          # Check if there are more pages and fetch them
          has_more=$(cat notion_page1.json | python3 -c "import sys,json; d=json.load(sys.stdin); print(d.get('has_more', False))")
          
          if [ "$has_more" = "True" ]; then
            echo "ðŸ“„ Fetching additional pages..."
            cursor=$(cat notion_page1.json | python3 -c "import sys,json; d=json.load(sys.stdin); print(d.get('next_cursor', ''))")
            page=2
            
            while [ "$has_more" = "True" ] && [ $page -le 20 ]; do
              curl -s -X POST \
                "https://api.notion.com/v1/data_sources/848a619d55134f528b6e97a1d284c465/query" \
                -H "Authorization: Bearer $NOTION_TOKEN" \
                -H "Notion-Version: 2025-09-03" \
                -H "Content-Type: application/json" \
                -d "{\"page_size\": 100, \"start_cursor\": \"$cursor\"}" > notion_page${page}.json
              
              has_more=$(cat notion_page${page}.json | python3 -c "import sys,json; d=json.load(sys.stdin); print(d.get('has_more', False))")
              cursor=$(cat notion_page${page}.json | python3 -c "import sys,json; d=json.load(sys.stdin); print(d.get('next_cursor', ''))")
              echo "  Page $page fetched"
              page=$((page + 1))
            done
          fi
          
          echo "âœ… All pages fetched"
          
      - name: Process Pick List Data
        run: |
          cat > process_picks.py << 'PYTHON'
          import json
          import glob
          from datetime import datetime
          
          all_results = []
          
          # Load all pages
          for filename in sorted(glob.glob('notion_page*.json')):
              with open(filename) as f:
                  data = json.load(f)
                  if 'results' in data:
                      all_results.extend(data['results'])
          
          print(f"ðŸ“Š Total samples: {len(all_results)}")
          
          picks = {}
          sample_info = {}
          
          for page in all_results:
              props = page.get('properties', {})
              
              # Get Injection ID (title property)
              injection_id = None
              for key, value in props.items():
                  if value.get('type') == 'title':
                      titles = value.get('title', [])
                      if titles:
                          injection_id = ''.join(t.get('plain_text', '') for t in titles)
                      break
              
              if not injection_id:
                  continue
              
              # Get Pick List (select property)  
              pick_list = props.get('Pick List', {})
              if pick_list.get('type') == 'select' and pick_list.get('select'):
                  pick_name = pick_list['select'].get('name')
                  if pick_name:
                      picks[injection_id] = [pick_name]
              
              # Also get Reserved for additional info
              reserved = props.get('Reserved', {})
              if reserved.get('type') == 'multi_select':
                  reserved_names = [item.get('name') for item in reserved.get('multi_select', [])]
                  sample_info[injection_id] = {
                      'reserved': reserved_names
                  }
          
          output = {
              'lastSync': datetime.utcnow().isoformat() + 'Z',
              'totalSamples': len(all_results),
              'samplesWithPicks': len(picks),
              'picks': picks,
              'sampleInfo': sample_info
          }
          
          with open('data/pick-list.json', 'w') as f:
              json.dump(output, f, indent=2)
          
          print(f"âœ… Processed {len(picks)} samples with Pick List")
          print(f"ðŸ“ Saved to data/pick-list.json")
          PYTHON
          
          mkdir -p data
          python3 process_picks.py
          
          echo ""
          echo "ðŸ“‹ Generated pick-list.json:"
          cat data/pick-list.json
          
      - name: Commit and Push
        run: |
          git config user.name "GitHub Actions"
          git config user.email "actions@github.com"
          
          git add data/pick-list.json
          
          if git diff --staged --quiet; then
            echo "ðŸ“­ No changes to commit"
          else
            git commit -m "ðŸ”„ Update pick list - $(date -u +'%Y-%m-%d %H:%M') UTC"
            git push
            echo "âœ… Changes pushed!"
          fi
